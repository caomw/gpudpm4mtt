\documentclass{article}

	\usepackage{fullpage} % Include this if you want to cram lots of things on a page
	 
	\usepackage{amsmath} % these are standard macro packages of the American Mathematical Society
	\usepackage{amssymb}
	%\usepackage{stmaryrd}
	
	\usepackage{epsfig} % if you want figures
	
	\usepackage[margin=1.5in]{geometry}
	
	\usepackage[numbers]{natbib}
	
	
	
%	\usepackage{fancyhdr} % These 4 lines are needed to set up the running  header
%	\fancyhead[LE,RO]{Test Document}
%	\fancyhead[RE,LO]{\thepage}
%	\pagestyle{fancy}

\newcommand{\matlab}[1]
{\centerline{\parbox{.9\textwidth}{\noindent\textsc{\bf MATLAB:} #1}}}

\newcommand{\code}[1]{\texttt{#1}}

\newcommand {\x}{\V{x}}
\newcommand {\y}{\V{y}}
\newcommand {\V}[1]{\mbox{\boldmath$#1$}}








\begin{document}

\title{Literature Review}
\author{Willie}
\maketitle
\mbox{}






\subsection*{Overall Paper Breakdown}
\vspace{6pt}
Papers relating to techniques for the general tracking of multiple objects are split into four broad topics: those related to the mean-shift procedure (a very popular and effective technique in recent times), those related to object tracking with the use of color, those related to foreground modeling and motion extraction, and those related to cluster-based object tracking. \\
\\
\\
The Mean-Shift Procedure \\
a.k.a Kernel Based Object Detection \\
\\ 
The mean-shift procedure attempts to provide a robust way for non-rigid objects to be tracked. In this case, tracking refers to the task of maintaining the location of an object after its initial position has been specified. The mean shift procedure (a derivation and classic overview of which can be found in \cite{fukunaga_1975}and \cite{cheng_1995}) is a simple iterative procedure that repeatedly shifts each data point to the weighted average of data points in its neighborhood; it has been proven that this process converges for each data point. Additionally, the process (in particular, the specification of the neighborhood and the weight-distribution when calculating the weighted mean of nearby data points) is generalized so that multiple kernels can be specified and used to allow for varied clustering behaviors. It can be shown that, through this procedure, each data point becomes associated with a local point of high density (dependent upon the underlying weight distribution specified by the kernel) which naturally allows for clustering \cite{cheng_1995}. The mean shift algorithm has been implemented successfully to allow for a sort of kernel-based object tracking (\cite{comaniciu_2003}, \cite{comaniciu_1999}, \cite{comaniciu_2000}). Given the current position of an object at a given frame, the goal of tracking is often to find a nearby position in the next frame that has the most similar distribution over some common set of features. Usually this must be done through an exhaustive search, comparing the similarity of distributions at each nearby position with that at the current position. However, if a certain type of `isotropic kernel' (mean-shift kernel) known as the Bhattacharyya coefficient is chosen as a similarity metric between the feature distributions at two positions, it creates a smooth function where gradient descent techniques can be used to quickly converge upon an optimal subsequent position without using an exhaustive search. Many papers are concerned with applying this kernel-based object tracking scheme to different sets of features or with different kernels. Additionally, the scheme has been attempted with an adaptive kernel whose shape, scale, and orientation is influenced by a target being tracked \cite{wang_2004}, with a kernel adjusted by the estimated centroid of a tracked target \cite{mehmood_2009}, and with a heirarchical version of the mean-shift procedure \cite{dementhon_2002}. \\
\\
\\
Object Tracking with the Use of Color \\
\\
Color has long been used to track non-rigid objects; again, in this case, tracking refers to the task of maintaining the location of an object after its initial position has been specified. In general, these schemes operate by modeling an object with some color-based appearance model, and using this model to find the object in subsequent frames \cite{elgammal_2001}. One classic approach involves modeling the color of a target using a Gaussian mixture model (GMM), and choosing a subsequent target position by searching a surrounding area for a position that yields the most similar GMM. Furthermore, the GMM is often allowed to adapt over time, and slowly change to model changes in lighting or other smooth time-based variations in the target's color \cite{raja_1998}, \cite{mckenna_1999}, \cite{jepson_2003}. Additionally, color has been successfully applied as the feature in the mean-shift procedure (kernel-based method) for tracking \cite{comaniciu_2003}, \cite{perez_2002}, \cite{nummiaro_2003}, \cite{lee_2011}. \\
\\
\\
Foreground Detection\\
a.k.a Frame Differencing, Image Differencing, Background Subtraction, Motion Detection\\
\\
Foreground detection, frame differencing, background subtraction, and motion detection all refer to slighly different things. Frame differencing and background subtraction involve comparing pixel values, or groups of pixel values, from two images, to detect a change surpassing some threshold. Often, background subtraction refers to comparing an image containing targets with an image of the background without targets, while frame or image differencing refers to comparing two subsequent images in a video. Foreground detection might also refer to a similar comparison technique, but also might be achieved by modeling pixel values. For example, sensitive foreground detection has been carried out robustly by modeling each pixel over time in order to infer a probability distribution over pixel values; if the pixel takes on a very unlikely value at a future time, it is marked as a foreground pixel \cite{stauffer_1999}, \cite{elgammal_2000}, \cite{elgammal_2002}. These pixel modeling techniques have been adapted to allow for time-dependent pixel value probability distributions, which help account for slighlty changing backgrounds, such as those caused from slight movements of background objects (for example, trees in outdoor scenes). Note that these techniques treat each pixel independently; this has a tendency to cause errors in foreground detection, resulting in fragmentation of foreground images (which is problematic as many of these methods intend to blob the foreground objects after detection in order to perform segmentation and locate objects' centroids). Post processing has been applied to add information regarding the edges of objects in an attempt to decrease fragmentation \cite{turdu_2007}. Similar to foreground detection, motion detection might also refer to a comparison technique or to other ways of extracting movement from an image, such as through techniques involving optical flow (a calculation based on a so called `generalized gradient model' of an image, which attempts to capture the speed and direction of movement over areas in the image) \cite{horn_1981}, \cite{bobick_2001}. In \cite{black_2000}, a motion detection and object tracking method is developed based on the relative motion of moving objects' boundaries, which are again found through analysis of optical flow.\\
\\
\\
Clustering Based Object Tracking \\
a.k.a. Most Similar Things to Our Project \\
\\
Clustering based object tracking and detection schemes typically attempt to either detect objects or simultaneously detect and track objects using minimal, easily extracted, or general information about a scene and the targets within it. These techniques often start with foreground (e.g. movement) or color data from each frame in a video, and attempt to automatically perform segmentation and tracking with temporal clustering (where clusters are somehow present at or shared between multiple frames). This differs from blob-based tracking approaches, where a pixel is assigned to the foreground or to a specific, segmented blob (each of which represents a target) such as in \cite{stauffer_1999}. In \cite{pece_2002}, foreground positions are found via frame differencing and modeled with a sequence of GMMs.\\
\cite{beleznai_2006}
\cite{dickinson_2005}
\cite{schiele_2006}
  \\
\\









\subsection*{Some Terminology}
\vspace{6pt}
1. Multiple Target Tracking (MTT) \\
\\
a.k.a. Multitarget Tracking, Data Association \\
\\
Definition: An algorithm that takes as input a collection of data points, where each point represents the center position of an object at a given time, and returns a partition of these points; each element of the partition is comprised of a sequence of data points and represents a target's position at successive points in time. \\
\\
\\
2. Target Detection \\
\\
a.k.a. Target Recognition, Target Localization, Target Representation, Target Segmentation, Object Detection \\
\\
Definition: The act of deducing whether an image contains a specified target and, if it is present, locating the target's position. \\
\\
\\
3. Visual Multiple Target Tracking (VMTT) \\
\\
a.k.a. Video Tracking, Video Multiple Target Tracking, 2D Tracking, Object Tracking, Multi-Object Video Tracking \\
\\
Definition: An algorithm that tracks the time-varying positions of multiple targets in a video; it typically involves target detection to find the center position of each target at each point in time, and MTT on the found target centers to accomplish tracking.
\\
\\
4. Tracking \\
\\
a.k.a most terms in 3.
\\
Definition: Given the current position of a target, tracking algorithms find a likely subsequent position of a target (note that this is distinct from the VMTT definition above, as it does not involve target detection; however, terms describing VMTT and tracking are ofen used to refer to both).
\\
\\
5. Background Subtraction\\
\\
a.k.a frame differencing, image differencing, motion detection \\
\\
Definition: The terms above all involve comparing pixel values, or groups of pixel values, from two images, to detect a change surpassing some threshold. Often 'background subtraction' refers to comparing an image containing targets with an image of the background without targets, while 'frame/image differencing' refers to comparing two subsequent images in a video. \\
\\
\\




\subsection*{Overview}
\vspace{6pt}
Visual multiple target tracking (VMTT) involves tracking the positions of multiple targets in a video. VMTT algorithms typically carry out two main tasks: the first is target detection, the task of finding the positions of targets within an image, and the second is multiple target tracking (MTT), the task of grouping the positions into sequences, where each sequence represents a target's position at successive points in time. \\
\\
MTT algorithms are well studied, and, given the positions of targets in each frame of a video, have been shown to achieve tracking with high accuracy \cite{blackman_2004}. General methods for target detection have had less success. Many current target detection methods are limited to specific types of targets as they perform detection by catering to some unique visual or structural characteristic of the target. These methods are often less robust when applied to targets that change appearance, orientation, or scale, and to scenes with diverse background characteristics. Furthermore, even with a target-specific feature to aid detection, there are often problems with image segmentation (decisions as to where one object ends and a neighboring object begins) and with estimating the number of objects in a scene.  \\
\\
The goal of this project is to apply a time dependent Dirichlet process mixture model known as the generalized Polya urn Dirichlet process mixture model (GPUDPM) to videos containing multiple targets in a way that tracks the targets' positions without requiring explicit target detection. We hope to allow for a 	single flexible VMTT algorithm that can be applied to scenes with different numbers of targets, with diverse backgrounds, whose targets display a wider range of visual and structural characteristics, and where there are time-varying shifts in targets' characteristics, perspectives, or orientations.\\






\subsection*{MTT}
\vspace{6pt}
At its most basic, MTT can be approached with the Global Nearest Neighbor (GNN) technique \cite{blackman_2004}, where tracks are formed by associating each observation with its nearest neighbor, under the constraint that an observation can be associated with no more than one track. Often, GNN is performed until a problem such as a conflicting track assignment occurs, whereupon a more sophisticated technique is used. As for these more-complex methods, there are two classic MTT algorithms that form a basis for many modern techniques. The first is called multiple hypothesis tracking (MHT) \cite{singer_1974, reid_1979, blackman_2004}, in which (at its most basic), for each observation, a set of potential neighbors are considered for association; the process is then repeated recursively for each potential neighbor, forming a tree-like structure. Most branches die along the way due to lack of potential neighbors, but eventually (ideally) only one branch remains, and it is considered most-likely to be the true path. MHT is computationally expensive, but has gained popularity in recent times due to increases in computational capabilities \cite{blackman_2004}. The second classic MTT algorithm is known as the Joint Probabilistic Data Association (JPDA) method \cite{barshalom_1975, kirubarajan_2004}. In contrast to GNN, where the nearest potential neighbor is chosen as the associated position, and MHT, where all potential neighbors are followed until only one remains, JPDA computes a probability that each potential neighbor (that pass an initial validation test) is the next position of the current track, and predicts the next position as a probability-weighted combination of all potential positions. In this way, JPDA acts similar to another MTT technique known as Recursive Bayesian Filtering (RBF), where the position of a target at a future step is predicted, and this prediction allows for subsequent points to be associated to a track with higher accuracy. Techniques involving RBF often make use of a Kalman or particle filter, and these methods are often incorporated with the other algorithms mentioned in this section. Pulford \cite{pulford_2005} gives a thorough overview of `classic' and `modern' data association algorithms (and gives the details of 35 different MTT algorithms). Fox et al. \cite{fox_2006} uses a Dirichlet Process prior to estimate the number of targets in an MTT scheme. \\




\subsection*{VMTT}
\vspace{6pt}
Qu et al. \cite{qu_2007} term computer vision related MTT `visual multiple-target tracking', and give a thorough overview of the topic. MacCormick and Blake \cite{maccormick_1999} focus on distinguishing between foreground and background objects and use it to help perform target detection in videos where objects occlude each other (i.e. where one object overlaps and blocks another). Isard and MacCormick \cite{isard_2001} present a people-tracking algorithm that deduces foreground and background objects probabilistically, without the typical strategy of selecting foreground objects prior to MTT; the authors also talk about ways in which their techniques allow for tracking variable numbers of objects and objects that enter and exit the videos. Zhao and Nevatia \cite{tao_2004} make use of human shape models to better the MTT accuracy when tracking crowds of people. Tao et al. \cite{tao_1999} use sampling to perform Bayesian inference and focus on handling occlusion, addition, and deletion of targets. Rasmussen et al. \cite{rasmussen_2001} apply a version of the joint probabilistic data association filter to certain shape and texture features they are able to extract from video targets (i.e. in the case of conflicting track assignments, successive positions are chosen based on a combination of probabilities of potential positions which are each dependent, in part, upon these shape and texture features). Khan et al. \cite{khan_2005}, present an MCMC-based particle filter that also introduces a Markov random field to model the interactions of targets when they are within certain ranges of other targets (applied to videos of ants, arguing that an ant's behavior is highly influenced by nearby ants). Smith et al. \cite{smith_2005} aim to increase the efficiency in the multiple hypothesis tracker while incorporating target features such as color into their model. McKenna et al. \cite{mckenna_2000} use color and gradient information to perform background subtraction on videos of people; their model then has a heirarchical structure where groups of occluding people are first tracked, and then later separated to track each person separately, using color information. Yamamoto et al. \cite{yamamoto_1995} uses optical flows (calculated based on a so called `generalized gradient model' of an image, which attempts to capture the speed and direction of movement over areas in the image) to carry out multiple target tracking.\\




\subsection*{Generalized Polya Urn Dirichlet Process Mixture Model}
\vspace{6pt}
Caron et al. \cite{caron_2007} introduce the generalized Polya urn Dirichlet process mixture model. Gasthaus et al. \cite{gasthaus_2008} apply this model to the spike-sorting problem.



\begin{small}
\bibliographystyle{plainnat}
\bibliography{refs_lit_review} 
\end{small}






%\subsection*{Overview 2}
%\vspace{6pt}
%The phrase `multiple target tracking' (MTT) has been used to refer to two distinct but related problems: the first is the problem of detecting and tracking the positions of multiple targets of interest in a video, and the second is the problem of associating data points, where each data point is assumed to represent the centroid of some target whose position varies with time. The first is a problem in the field of machine vision and may use data association techniques from the second to accomplish MTT after targets of interest are detected and their positions represented as points.\\
%\\
%The goal of this project is to apply the generalized Polya urn Dirichlet process mixture model (GPUDPM) to videos containing multiple targets in a way that accomplishes data association without requiring explicit target detection. We hope to allow for a single flexible MTT algorithm that can handle videos with different numbers of targets, with diverse backdrops, whose targets display a wide range of characteristics, and where there are time-varying shifts in targets' characteristics, perspectives, or orientations.\\
%\\
%\\
%The following are summaries of papers focusing on MTT as it relates to the association of target centroids, MTT as it relates to machine vision, and the generalized Polya urn Dirichlet process mixture model.



% Hue et al. \cite{hue, 2002} introduce particle filters for MTT. 

%Oh et al. (Markov Chain Monte Carlo Data Association for General Multiple-Target Tracking Problems, 2004) uses an MCMC approach to perform general data association. 






% VMTT
%Papers on this topic often involve algorithms that have a target detection phase (where the centroids of potential targets are collected, often by looking for specific target features) and a data association phase (where the centroids are sequenced in order to carry out tracking).\\



\end{document}