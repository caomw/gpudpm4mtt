\documentclass{article}

\usepackage{fullpage} % Include this if you want to cram lots of things on a page 
\usepackage{amsmath} % these are standard macro packages of the American Mathematical Society
\usepackage{amssymb}
%\usepackage{stmaryrd}
\usepackage{epsfig} % if you want figures
\usepackage[margin=1.5in]{geometry}
% \usepackage[numbers]{natbib}
\usepackage[square]{natbib}
\newcommand{\matlab}[1]
{\centerline{\parbox{.9\textwidth}{\noindent\textsc{\bf MATLAB:} #1}}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand {\x}{\V{x}}
\newcommand {\y}{\V{y}}
\newcommand {\V}[1]{\mbox{\boldmath$#1$}}
\newcommand{\tab}{\hspace*{2em}}







\begin{document}

\title{Literature Review}
\author{Willie}
\maketitle
\mbox{}





\subsection*{Outline and Terminology}
\vspace{6pt}
\begin{enumerate}
\item Multiple Target Tracking (MTT)
	\begin{enumerate}
	\item a.k.a. Point MTT, Multitarget Tracking, Data Association, Point Matching, Plot Association
	\item Definition: (will include later)
	\item Multiple Hypothesis Tracking (MHT), Joint Probabilistic Data Association Filter (JPDAF), and their variants and spin-offs
		\begin{enumerate}
		\item These algorithms may be used to track targets in videos if they can be represented as points.
		\end{enumerate}
	\end{enumerate}
\item Visual Object Tracking (VOT)
	\begin{enumerate}
	\item a.k.a. Video Tracking, Target Tracking, Visual Single Object Tracking, 2D Tracking, `Tracking of non-rigid objects'
	\item Definition: (will include later)
	\item Recursive Bayesian filtering
	\item Mean-shift methods
	\item Color tracking % (particularly, GMMs and `adaptive' stuff)
	\item These can be extended to multiple targets if detection / initialization is given (sometimes involve more sophisticated techniques when multiple targets introduced).
	\end{enumerate}
\item Foreground Extraction and Object Detection
	\begin{enumerate}
	\item a.k.a. Foreground segmentation, background modeling, frame differencing, background subtraction, motion detection, and \\
	a.k.a. Target localization, target representation, target segmentation 
	\item Definition: (will include later)
	\item Foreground / Background Modeling
		\begin{enumerate}
		\item GMM for background / foreground modeling (many studies)
		\end{enumerate}
	\item Motion detection, frame differencing, background subtraction
	\item Segmentation
	\end{enumerate}
\item Multiple Visual Object Tracking and Detection
	\begin{enumerate}
	\item a.k.a Multiple Target Tracking and Localization
	\item Definition: (will include later) 
	\item blob tracking
		\begin{enumerate}
		\item foreground detection (motion, thresholding, subtraction, color), segmentation (pixel assignment), (sometimes) centroid placement (localization?), and (sometimes) point MTT.
		\end{enumerate}
	\item clustering methods for automated segmentation and tracking
		\begin{enumerate}
		% \item Scene modeling (often uses Gaussians perpetuated over time, though each one isn't meant to represent a single target, i.e. doesn't intend to perform segmentation).
		\item Pece cluster tracker on motion (time-varying GMM with additions, applied to frame differencing)
		\item Mean-shift time-dependent clustering (1 paper)
		%  \item Other papers mentioned in Pece
		% \item Clustering feature points
		% \item gpudpm4mtt
		\end{enumerate}
	\end{enumerate}
\end{enumerate}




\subsection*{Related Work}
\vspace{6pt}
The follow sections provide details on work related to the automated detection and tracking of objects. The following numbered sections correspond to the numbers in the outline above.




\subsection*{1. Multiple Target Tracking (MTT)}

\subsubsection*{(a)-(c)}
At its most basic, MTT can be approached with the Global Nearest Neighbor (GNN) technique \citep{blackman_2004}, where tracks are formed by associating each observation with its nearest neighbor, under the constraint that an observation can be associated with no more than one track. Often, GNN is performed until a problem such as a conflicting track assignment occurs, whereupon a more sophisticated technique is used. As for these more-complex methods, there are two classic MTT algorithms that form a basis for many modern techniques. The first is called multiple hypothesis tracking (MHT) \citep{singer_1974, reid_1979, blackman_2004}, in which, for each observation, a set of neighbors is collected as potentials for association; the process is then repeated recursively for each potential neighbor, forming a tree-like structure of possible paths. Once the possible branches for a given path are enumerated, one branch is considered most-likely and is chosen as the true path (where branches may be favored if, for example, they are longer or adhere to some expected behavior of the target). MHT is computationally expensive, but has gained popularity due to increases in computational capabilities \citep{blackman_2004}. The second classic MTT algorithm is known as the Joint Probabilistic Data Association (JPDA) method \citep{barshalom_1975, kirubarajan_2004}. In contrast to GNN, where the nearest potential neighbor is chosen as the associated position, and MHT, where all potential neighbors are followed until only one remains, JPDA computes a probability that each potential neighbor (that pass an initial validation test) is the next position of the current track, and predicts the next position as a probability-weighted combination of all potential positions. In this way, JPDA acts similar to another MTT technique known as Recursive Bayesian Filtering (RBF), where the position of a target at a future step is predicted, and this prediction allows for subsequent points to be associated to a track with higher accuracy. Techniques involving RBF often make use of a Kalman or particle filter, and these methods are often incorporated with the other algorithms mentioned in this section. Pulford gives a thorough overview of `classic' and `modern' data association algorithms (and gives the details of 35 different MTT algorithms) \citep{pulford_2005}. Taking a different approach to estimating the number targets, Fox et al. uses a Dirichlet Process prior to estimate the number of targets in an MTT scheme \citep{fox_2006}.




\subsection*{2. Visual Object Tracking (VOT)}

\subsubsection*{(a)-(b)}
Given the position of a target in the current frame of a video, VOT is the task of predicting the target's position in the following frame. VOT is not concerned with detecting new targets, but instead with maintaining the location of an object after its initial position has been specified. VOT is also sometimes used to refer to the task of maintaining the shape or size of a target over time, in addition to its position. Most VOT schemes operate by considering the region that represents a target in a given frame of a video, and looking in the vicinity of this region in a subsequent frame for the most similar region. Areas of research are primarily concerned with ways to represent the appearance of targets, predict future positions of targets, accurately or quickly find similar regions in successive frames, and handle troublesome targets (for example, targets which may appear, dissapear, or have time-varying characteristics) \citep{yilmaz_2006}.

\subsubsection*{(c)}
Recursive Bayesian filtering involves the task of estimating the position of a target from noisy measurements. (This section is not finished. Need to discuss numerous methods which use particle filtering techniques for object tracking. Are these techniques even very similar / under the same umbrella?)

\subsubsection*{(d)}
The mean-shift procedure (also known as `kernel-based object tracking') attempts to provide a robust way for non-rigid objects to be tracked. This method is beneficial because it optimizes the search for the `next' position of an object (i.e. the search for the region in a frame which is most similar to a target region in the previous frame). This procedure--a derivation and overview of which can be found in \citep{fukunaga_1975, cheng_1995}--involves an iterative algorithm that repeatedly shifts each data point to the weighted average of data points in its neighborhood; it has been proven that this process converges for each data point. Additionally, the process (in particular, the specification of the neighborhood and the weight-distribution when calculating the weighted mean of nearby data points) is generalized so that multiple kernels can be specified and used to allow for varied clustering behaviors. It can be shown that, through this procedure, each data point becomes associated with a local point of high density (dependent upon the underlying weight distribution specified by the kernel) which naturally allows for clustering \citep{cheng_1995}. The mean shift algorithm has been implemented successfully to allow for a sort of kernel-based object tracking \citep{comaniciu_2003, comaniciu_1999, comaniciu_2000}. Given the current position of an object at a given frame, the goal of tracking is often to find a nearby position in the next frame that has the most similar distribution over some common set of features. Usually this must be done through an exhaustive search, comparing the similarity of distributions at each nearby position with that at the current position. However, if a certain type of `isotropic kernel' (mean-shift kernel) known as the Bhattacharyya coefficient is chosen as a similarity metric between the feature distributions at two positions, it creates a smooth function where gradient descent techniques can be used to quickly converge upon an optimal subsequent position without using an exhaustive search. Many papers are concerned with applying this kernel-based object tracking scheme to different sets of features or with different kernels. Additionally, the scheme has been attempted with an adaptive kernel whose shape, scale, and orientation is influenced by a target being tracked \citep{wang_2004}, with a kernel adjusted by the estimated centroid of a tracked target \citep{mehmood_2009}, and with a heirarchical version of the mean-shift procedure \citep{dementhon_2002}. 

\subsubsection*{(e)}
Color has long been used to track non-rigid objects; again, in this case, tracking refers to the task of maintaining the location of an object after its initial position has been specified. In general, these schemes operate by modeling an object with some color-based appearance model, and using this model to find the object in subsequent frames. One classic approach involves modeling the color of a target (in particular, a distribution over the hue-saturation space of a target region) with a Gaussian mixture model (GMM), and choosing subsequent target positions by searching surrounding areas for regions that yield similar GMMs. Furthermore, the GMM is often allowed to adapt over time, and slowly change to model changes in lighting or other smooth time-based variations in the target's color \citep{raja_1998, mckenna_1999, jepson_2003}. Others have attempted to abstract this work with a non-parametric color modeling approach based on kernel density estimation, which does not assume a specific underlying distribution (such as the Gaussian mixture in the previous case) and instead converges to reasonable distribution that depends on the data \citep{elgammal_2001}. Additionally, color has been successfully applied as the feature in the mean-shift procedure (kernel-based method) for tracking \citep{comaniciu_2003, perez_2002, nummiaro_2003, lee_2011}.

\subsubsection*{(f)}
VOT schemes are easily extendable to tracking multiple targets; at the most basic level, this involves initializing multiple targets and running an instance of (single) VOT for each, either simultaneously or in succession \citep{perez_2002}. Furthermore, if performed simultaneously, the tracking of each target can be made dependent upon characteristics of other targets (such as their proximity) to resolve errors and improve tracking (such as those caused by the incorrect merging of two targets) \citep{khan_2004, vermaak_2003} . 




\subsection*{3. Foreground Extraction and Object Detection}

\subsubsection*{(a)-(b)}
The following methods are not concerned with tracking, but instead with the detection of and differentiation between individual objects in a given frame (or over a sequence of frames) of a video. Usually, objects of interest for tracking are in the foreground of a scene; as such many of the following techniques involve attempts to separate the foreground of a scene from the background. Another issue is that of segmentation, or deciding which pixels are associated with which object; this is also what determines the number of objects present in a scene. 

\subsubsection*{(c)}
Foreground extraction, foreground segmentation, foreground detection, and background modeling all refer to the task of deducing which pixels represent foreground objects (i.e. objects likely to be desired for tracking), and which represent background objects. Foreground extraction, though possible to carry out by following certain heuristics involving temporal changes in pixel value characteristics (see section (d)), is often achieved, instead, using model-oriented techniques. For example, foreground extraction has been robustly carried out by modeling each pixel over time in order to infer a probability distribution over pixel values; if the pixel takes on a very unlikely value at a future time, it is marked as a foreground pixel at that point \citep{stauffer_1999, elgammal_2000, elgammal_2002}. These pixel modeling techniques have been adapted to allow for time-dependent probability distributions over pixel values, which help account for slighlty changing backgrounds, such as those caused from brief movements of background objects (for example, trees in outdoor scenes). Note that these techniques treat each pixel independently; this has a tendency to cause errors in foreground detection, resulting in fragmentation of foreground images (which is problematic as many of these methods intend to blob the foreground objects after detection in order to perform segmentation and locate objects' centroids). Post processing has been applied to add information regarding the edges of objects in an attempt to decrease fragmentation \citep{turdu_2007}. Others have attempted to achieve better foreground modeling in cases where the foreground and background exhibit similar color distributions (the so called `color similarity problem') by, for example, incorporating models of the foreground into a typical background model (such as the one described above) \citep{gallego_2009, mchugh_2009}.

\subsubsection*{(d)}
Frame differencing and background subtraction involve comparing pixel values, or groups of pixel values, between two images, to detect a change surpassing some threshold. The goal of these techniques is to find locations in a scene that display motion, and to deem these moving areas the foreground of a scene.  Often, background subtraction refers to comparing an image containing targets with an image of the background without targets or with some model of the background that is learned as the video progresses (in these cases, objects that do not move throughout a scene will be treated as the background), while frame or image differencing refers to comparing two subsequent images in a video. Frame differencing has been used as the sole data extraction method for object tracking schemes with success \citep{pece_2002, beleznai_2006, chu_2007}, and also as a secondary data extraction method to help improve the accuracy of object tracking schemes \citep{perez_2002}. In addition to the two techniques mentioned above, there exists other ways of extracting movement from an image, such as through techniques involving optical flow (a calculation based on a so called `generalized gradient model' of an image, which attempts to capture the speed and direction of movement over areas in the image) \citep{horn_1981, bobick_2001}. In \citep{black_2000}, a motion detection and object tracking method is developed based on the relative motion of moving objects' boundaries, which are again found through analysis of optical flow.

\subsubsection*{(e)}
Target localization, target representation, and target segmentation all relate to the task of finding the position of objects in a scene. In the context of the foreground extraction described previously, the process of segmenting foreground pixels into distinct foreground objects allows for object localization. Segmentation can be very simple: the watershed transform, mean-shift procedure, and other basic clustering algorithms have been used directly on foreground extracted pixels to accomplish segmentation \citep{yang_2006}.




\subsection*{4. Multiple Visual Object Tracking and Detection}

\subsubsection*{(a)-(b)}
There are certain methods which attempt to combine object detection and VOT in order to provide a start-to-finish technique for temporal object detection (detecting a given object throughout its time in a scene). Some methods involve foreground extraction and segmentation as initialization for VOT, which results in the tracking of all objects present at the beginning of a scene, while others attempt more sophisticated methods in order to handle scenes where objects enter and exit throughout.

\subsubsection*{(c)}
Blob tracking often refers to the task of foreground extraction (in blob trackers this is often done by extracting pixels whose value is above some threshold, which only works for videos where foreground objects have pixel values that are very dissimilar to those of background objects), segmentation of foreground pixels, and MTT, where each `blob' created during segmentation is treated as a point particle. More sophisticated blob tracking may involve statistical appearance models for robust foreground extraction, such as those described in 3.(c), which allow for background subtraction in cases where the foreground and background pixels have similar colors or where the characteristics of the foreground targets show strong temporal dependence \citep{stauffer_1999, wren_1997, kjeldsen_1996}. Blob trackers have even incorporated the ability to estimate the correct number of targets in a scene and introduce recursive Bayesian filtering for improved VOT \citep{isard_2001}.

\subsubsection*{(d)}
Clustering based object tracking and detection schemes typically attempt to either detect objects or simultaneously detect and track objects using minimal, easily extracted, or general information about a scene and the targets within it. These techniques often start with foreground (e.g. movement) pixels, color data from each frame in a video, or so called `feature points' (described in the following section) and attempt to automatically perform segmentation and tracking with temporal clustering (where clusters are somehow present at or shared between multiple frames). This differs from blob-based tracking approaches, where a pixel is assigned to the foreground or to a specific, segmented blob (each of which represents a target) at each frame.

\paragraph*{i}
In \citep{pece_2002}, foreground positions are found via frame differencing and modeled with a sequence of GMMs. Pece provides criteria for eliminating, merging, and estimating the correct number of clusters. Additionally, he uses simple heuristics for the initialization of clusters. Tracking is carried out on a dataset consisting of varied objects, and this method is able to track the various types of objects, though fails when objects become too close in space.

\paragraph*{ii}
The mean-shift procedure was used by \cite{beleznai_2006} to perform clustering on foreground pixels extracted via frame-differencing. The authors promote this technique over that in \citep{pece_2002}, and say that it has a better ability to keep nearby density maxima (in the difference pixels data) separate.

% \paragraph*{ii}



% \cite{dickinson_2005}
% \cite{schiele_2006}
% Another method of detecting objects in the foreground involves extraction of objects' `feature points'. These could be any sort of characteristic feature able to be extracted




% \subsection*{Generalized Polya Urn Dirichlet Process Mixture Model}
% \vspace{6pt}
% Caron et al. \cite{caron_2007} introduce the generalized Polya urn Dirichlet process mixture model. Gasthaus et al. \cite{gasthaus_2008} apply this model to the spike-sorting problem.



\begin{small}
\bibliographystyle{plainnat}
\bibliography{refs_lit_review} 
\end{small}






%\subsection*{Overview 2}
%\vspace{6pt}
%The phrase `multiple target tracking' (MTT) has been used to refer to two distinct but related problems: the first is the problem of detecting and tracking the positions of multiple targets of interest in a video, and the second is the problem of associating data points, where each data point is assumed to represent the centroid of some target whose position varies with time. The first is a problem in the field of machine vision and may use data association techniques from the second to accomplish MTT after targets of interest are detected and their positions represented as points.\\
%\\
%The goal of this project is to apply the generalized Polya urn Dirichlet process mixture model (GPUDPM) to videos containing multiple targets in a way that accomplishes data association without requiring explicit target detection. We hope to allow for a single flexible MTT algorithm that can handle videos with different numbers of targets, with diverse backdrops, whose targets display a wide range of characteristics, and where there are time-varying shifts in targets' characteristics, perspectives, or orientations.\\
%\\
%\\
%The following are summaries of papers focusing on MTT as it relates to the association of target centroids, MTT as it relates to machine vision, and the generalized Polya urn Dirichlet process mixture model.



% Hue et al. \cite{hue, 2002} introduce particle filters for MTT. 

%Oh et al. (Markov Chain Monte Carlo Data Association for General Multiple-Target Tracking Problems, 2004) uses an MCMC approach to perform general data association. 






% VMTT
%Papers on this topic often involve algorithms that have a target detection phase (where the centroids of potential targets are collected, often by looking for specific target features) and a data association phase (where the centroids are sequenced in order to carry out tracking).\\



\end{document}